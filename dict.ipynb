{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 采用字典结构提取特征\n",
    "## 从原始数据输入到特征文件生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.引入三方库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.读取所需数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/train.csv')\n",
    "test =  pd.read_csv('../../data/test.csv')\n",
    "merchant = pd.read_csv('../../data/merchants.csv')\n",
    "new_transaction = pd.read_csv('../../data/new_merchant_transactions.csv')\n",
    "history_transaction = pd.read_csv('../../data/historical_transactions.csv')\n",
    "\n",
    "# 按照字典序进行编码\n",
    "def change_object_cols(se):\n",
    "    value = se.unique().tolist()    #取唯一值\n",
    "    value.sort()\n",
    "    return se.map(pd.Series(range(len(value)), index=value)).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.做数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hxz：对first_active_month编码，从年月变为1，2，3，4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_object_cols(se):\n",
    "    value = se.unique().tolist()    #取唯一值\n",
    "    value.sort()\n",
    "    return se.map(pd.Series(range(len(value)), index=value)).values\n",
    "\n",
    "## train&test\n",
    "# 对首次活跃月份进行编码\n",
    "se_map = change_object_cols(train['first_active_month'].append(test['first_active_month']).astype(str))\n",
    "#train['first_active_month'] = se_map[:train.shape[0]]\n",
    "#test['first_active_month'] = se_map[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['first_active_month'].unique().tolist().sort()\n",
    "#se_map\n",
    "#train['first_active_month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hxz: \n",
    "* 对'category_1', 'most_recent_sales_range', 'most_recent_purchases_range', 'category_4'编码，编码为1，2，3，4\n",
    "* 填充离散字典（category_cols），NA -> -1\n",
    "* 无穷值替换为最大值\n",
    "* 连续值用均值替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 商户信息\n",
    "# 1、根据业务含义划分离散字段category_cols与连续字段numeric_cols。\n",
    "category_cols = ['merchant_id', 'merchant_group_id', 'merchant_category_id',\n",
    "       'subsector_id', 'category_1',\n",
    "       'most_recent_sales_range', 'most_recent_purchases_range',\n",
    "       'category_4', 'city_id', 'state_id', 'category_2']\n",
    "numeric_cols = ['numerical_1', 'numerical_2',\n",
    "     'avg_sales_lag3', 'avg_purchases_lag3', 'active_months_lag3',\n",
    "       'avg_sales_lag6', 'avg_purchases_lag6', 'active_months_lag6',\n",
    "       'avg_sales_lag12', 'avg_purchases_lag12', 'active_months_lag12']\n",
    "\n",
    "# 2、对非数值型的离散字段进行字典排序编码。\n",
    "for col in ['category_1', 'most_recent_sales_range', 'most_recent_purchases_range', 'category_4']:\n",
    "    merchant[col] = change_object_cols(merchant[col])\n",
    "    \n",
    "# 3、为了能够更方便统计，进行缺失值的处理，对离散字段统一用-1进行填充。\n",
    "merchant[category_cols] = merchant[category_cols].fillna(-1)\n",
    "\n",
    "\n",
    "# 4、对离散型字段探查发现有正无穷值，这是特征提取以及模型所不能接受的，因此需要对无限值进行处理，此处采用最大值进行替换。\n",
    "inf_cols = ['avg_purchases_lag3', 'avg_purchases_lag6', 'avg_purchases_lag12']\n",
    "merchant[inf_cols] = merchant[inf_cols].replace(np.inf, merchant[inf_cols].replace(np.inf, -99).max().max())\n",
    "\n",
    "# 5、对于离散字段的缺失值处理方式也有多样，这里先使用平均值进行填充，后续有需要再进行优化处理。\n",
    "for col in numeric_cols:\n",
    "    merchant[col] = merchant[col].fillna(merchant[col].mean())\n",
    "    \n",
    "# 6、去除与transaction交易记录表格重复的列，以及merchant_id的重复记录。\n",
    "duplicate_cols = ['merchant_id', 'merchant_category_id', 'subsector_id', 'category_1', 'city_id', 'state_id', 'category_2']\n",
    "merchant = merchant.drop(duplicate_cols[1:], axis=1)\n",
    "merchant = merchant.loc[merchant['merchant_id'].drop_duplicates().index.tolist()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>merchant_group_id</th>\n",
       "      <th>numerical_1</th>\n",
       "      <th>numerical_2</th>\n",
       "      <th>most_recent_sales_range</th>\n",
       "      <th>most_recent_purchases_range</th>\n",
       "      <th>avg_sales_lag3</th>\n",
       "      <th>avg_purchases_lag3</th>\n",
       "      <th>active_months_lag3</th>\n",
       "      <th>avg_sales_lag6</th>\n",
       "      <th>avg_purchases_lag6</th>\n",
       "      <th>active_months_lag6</th>\n",
       "      <th>avg_sales_lag12</th>\n",
       "      <th>avg_purchases_lag12</th>\n",
       "      <th>active_months_lag12</th>\n",
       "      <th>category_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M_ID_838061e48c</td>\n",
       "      <td>8353</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.250000</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>-2.320000</td>\n",
       "      <td>13.916667</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M_ID_9339d880ad</td>\n",
       "      <td>3184</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.720000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.740000</td>\n",
       "      <td>1.291667</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.570000</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M_ID_e726bbae1e</td>\n",
       "      <td>447</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-82.130000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-82.130000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-82.130000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M_ID_a70e9c5f81</td>\n",
       "      <td>5026</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13.832993</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>21.650787</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>25.227709</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M_ID_64456c37ce</td>\n",
       "      <td>2228</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13.832993</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>21.650787</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>6</td>\n",
       "      <td>25.227709</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       merchant_id  merchant_group_id  numerical_1  numerical_2  \\\n",
       "0  M_ID_838061e48c               8353    -0.057471    -0.057471   \n",
       "1  M_ID_9339d880ad               3184    -0.057471    -0.057471   \n",
       "2  M_ID_e726bbae1e                447    -0.057471    -0.057471   \n",
       "3  M_ID_a70e9c5f81               5026    -0.057471    -0.057471   \n",
       "4  M_ID_64456c37ce               2228    -0.057471    -0.057471   \n",
       "\n",
       "   most_recent_sales_range  most_recent_purchases_range  avg_sales_lag3  \\\n",
       "0                        4                            4       -0.400000   \n",
       "1                        4                            4       -0.720000   \n",
       "2                        4                            4      -82.130000   \n",
       "3                        4                            4       13.832993   \n",
       "4                        4                            4       13.832993   \n",
       "\n",
       "   avg_purchases_lag3  active_months_lag3  avg_sales_lag6  avg_purchases_lag6  \\\n",
       "0            9.666667                   3       -2.250000           18.666667   \n",
       "1            1.750000                   3       -0.740000            1.291667   \n",
       "2          260.000000                   2      -82.130000          260.000000   \n",
       "3            1.666667                   3       21.650787            4.666667   \n",
       "4            0.500000                   3       21.650787            0.361111   \n",
       "\n",
       "   active_months_lag6  avg_sales_lag12  avg_purchases_lag12  \\\n",
       "0                   6        -2.320000            13.916667   \n",
       "1                   6        -0.570000             1.687500   \n",
       "2                   2       -82.130000           260.000000   \n",
       "3                   6        25.227709             3.833333   \n",
       "4                   6        25.227709             0.347222   \n",
       "\n",
       "   active_months_lag12  category_4  \n",
       "0                   12           0  \n",
       "1                   12           0  \n",
       "2                    2           0  \n",
       "3                   12           1  \n",
       "4                   12           1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 交易记录\n",
    "# 1、为了统一处理，首先拼接new和history两张表格，后续可以month_lag>=0进行区分。\n",
    "transaction = pd.concat([new_transaction, history_transaction], axis=0, ignore_index=True)\n",
    "del new_transaction\n",
    "del history_transaction\n",
    "gc.collect()\n",
    "\n",
    "# 2、同样划分离散字段、连续字段以及时间字段。\n",
    "numeric_cols = [ 'installments', 'month_lag', 'purchase_amount']\n",
    "category_cols = ['authorized_flag', 'card_id', 'city_id', 'category_1',\n",
    "       'category_3', 'merchant_category_id', 'merchant_id', 'category_2', 'state_id',\n",
    "       'subsector_id']\n",
    "time_cols = ['purchase_date']\n",
    "\n",
    "# 3、可仿照merchant的处理方式对字符型的离散特征进行字典序编码以及缺失值填充。\n",
    "for col in ['authorized_flag', 'category_1', 'category_3']:\n",
    "    transaction[col] = change_object_cols(transaction[col].fillna(-1).astype(str))\n",
    "transaction[category_cols] = transaction[category_cols].fillna(-1)\n",
    "transaction['category_2'] = transaction['category_2'].astype(int)\n",
    "\n",
    "# 4、进行时间段的处理，简单起见进行月份、日期的星期数（工作日与周末）、以及\n",
    "# 时间段（上午、下午、晚上、凌晨）的信息提取。\n",
    "transaction['purchase_month'] = transaction['purchase_date'].apply(lambda x:'-'.join(x.split(' ')[0].split('-')[:2]))\n",
    "transaction['purchase_hour_section'] = transaction['purchase_date'].apply(lambda x: x.split(' ')[1].split(':')[0]).astype(int)//6\n",
    "transaction['purchase_day'] = transaction['purchase_date'].apply(lambda x: datetime.strptime(x.split(\" \")[0], \"%Y-%m-%d\").weekday())//5                                                                    \n",
    "del transaction['purchase_date']\n",
    "\n",
    "\n",
    "# 5、对新生成的购买月份离散字段进行字典序编码。\n",
    "transaction['purchase_month'] = change_object_cols(transaction['purchase_month'].fillna(-1).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 表格合并\n",
    "# 6、处理完transaction与merchant两个表格后，为了方便特征的统一计算将其merge合并，重新划分相应字段种类。\n",
    "cols = ['merchant_id', 'most_recent_sales_range', 'most_recent_purchases_range', 'category_4']\n",
    "transaction = pd.merge(transaction, merchant[cols], how='left', on='merchant_id')\n",
    "\n",
    "numeric_cols = ['purchase_amount', 'installments']\n",
    "\n",
    "category_cols = ['authorized_flag', 'city_id', 'category_1',\n",
    "       'category_3', 'merchant_category_id','month_lag','most_recent_sales_range',\n",
    "                 'most_recent_purchases_range', 'category_4',\n",
    "                 'purchase_month', 'purchase_hour_section', 'purchase_day']\n",
    "\n",
    "id_cols = ['card_id', 'merchant_id']\n",
    "\n",
    "transaction[cols[1:]] = transaction[cols[1:]].fillna(-1).astype(int)\n",
    "transaction[category_cols] =transaction[category_cols].fillna(-1).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.进行特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317.2691900730133 s\n",
      "571.1122951507568 s\n",
      "822.6353559494019 s\n",
      "1074.5222661495209 s\n",
      "1333.3201110363007 s\n",
      "1595.9141898155212 s\n",
      "1852.6608669757843 s\n",
      "2111.0832810401917 s\n",
      "2364.9466364383698 s\n",
      "2617.400735139847 s\n",
      "2870.6861917972565 s\n",
      "3123.682358264923 s\n",
      "3377.0734837055206 s\n",
      "3631.2419126033783 s\n",
      "3885.53391122818 s\n",
      "4140.648916482925 s\n",
      "4394.289589643478 s\n",
      "4648.887509346008 s\n",
      "4900.354738950729 s\n",
      "5153.0943422317505 s\n",
      "5405.621023416519 s\n",
      "5658.705283403397 s\n",
      "5912.154780864716 s\n",
      "6167.972257852554 s\n",
      "6422.150825738907 s\n",
      "6677.293935060501 s\n",
      "7068.958474636078 s\n",
      "7671.519667387009 s\n",
      "8276.706960201263 s\n",
      "8884.248583555222 s\n",
      "9497.165215730667 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 初步策略，第一步采用字典结构统计用户的所有行为特征\n",
    "## 第二步，用户层面横向进行比较和特征提取\n",
    "## 第三步，纵向对比所有用户的交易记录\n",
    "\n",
    "features = {}\n",
    "card_all = train['card_id'].append(test['card_id']).values.tolist()\n",
    "for card in card_all:\n",
    "    features[card] = {}\n",
    "    \n",
    "\n",
    "columns = transaction.columns.tolist()\n",
    "idx = columns.index('card_id')\n",
    "category_cols_index = [columns.index(col) for col in category_cols]\n",
    "numeric_cols_index = [columns.index(col) for col in numeric_cols]\n",
    "\n",
    "\n",
    "\n",
    "# 记录运行时间\n",
    "s = time.time()\n",
    "num = 0\n",
    "for i in range(transaction.shape[0]):\n",
    "    va = transaction.loc[i].values\n",
    "    card = va[idx]\n",
    "    for cate_ind in category_cols_index:\n",
    "        for num_ind in numeric_cols_index:\n",
    "            col_name = '&'.join([columns[cate_ind], va[cate_ind], columns[num_ind]])\n",
    "            features[card][col_name] = features[card].get(col_name, 0) + va[num_ind]\n",
    "    num += 1\n",
    "    if num%1000000==0:\n",
    "        print(time.time()-s, \"s\")\n",
    "del transaction\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字典转dataframe\n",
    "df = pd.DataFrame(features).T.reset_index()\n",
    "del features\n",
    "cols = df.columns.tolist()\n",
    "df.columns = ['card_id'] + cols[1:]\n",
    "# 生成训练集与测试集\n",
    "train = pd.merge(train, df, how='left', on='card_id')\n",
    "test =  pd.merge(test, df, how='left', on='card_id')\n",
    "del df\n",
    "train.to_csv(\"../../preprocess/train_dict.csv\", index=False)\n",
    "test.to_csv(\"../../preprocess/test_dict.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
